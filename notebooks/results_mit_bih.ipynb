{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import sys \n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.feature_extraction.text as ft \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "import src.preprocessing.text_preprocessing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'ecg_mit'\n",
    "base_path = '../results/'\n",
    "path = f'{base_path}{FOLDER}/'\n",
    "full_paths = [f'{path}{file}' for file in os.listdir(path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "for p in full_paths:\n",
    "    name = p.split('/')[-1]\n",
    "    split = name.split('_')\n",
    "    method = '_'.join(split[1:-1])\n",
    "    n_words = split[-1].split('.')[0]\n",
    "    with open(p, 'r') as file:\n",
    "        if method not in files:\n",
    "            files[method] = {}\n",
    "        files[method][n_words] = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "tqdm.pandas()\n",
    "df = pd.read_csv('../data/mitdb_data/mitdb_ecg.csv', sep=';')\n",
    "vocabulary = df.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractor_timings(files: dict) -> pd.DataFrame:\n",
    "    methods = files.keys()\n",
    "    df = pd.DataFrame(columns=methods)\n",
    "    n_words_list = set()\n",
    "    method_list = set()\n",
    "    for method, words_dict in files.items():\n",
    "        method_list.add(method)\n",
    "        for n_words, info in words_dict.items():\n",
    "                df.loc[n_words, method] = info['timing']['extractor_fit']\n",
    "                n_words_list.add(n_words)\n",
    "                \n",
    "    df.index = df.index.astype('int')\n",
    "    df = df.sort_index()\n",
    "    df = df.apply(pd.to_timedelta)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].dt.total_seconds()\n",
    "    return df, method_list, n_words_list\n",
    "\n",
    "def plot_extractors_timings(df) -> plt.figure:\n",
    "    axes = df.plot(logy=True, logx=True, figsize=(16, 10))\n",
    "    axes.set_xlabel('# selected features')\n",
    "    axes.set_ylabel('runtime (sec)')\n",
    "    axes.set_label('runtime (sec)')\n",
    "    plt.title('Feature extractor runtimes vs number of the selected featues.')\n",
    "    plt.savefig('../figures/mit_bih_extractor_runtime_vs_n_features.png')\n",
    "    plt.close()\n",
    "\n",
    "def get_selected_words_per_extractor_per_n_words(files: dict, vocabulary, n_words_list, method_list):\n",
    "    df_dict = {}\n",
    "\n",
    "    for n_words in n_words_list:\n",
    "        df_dict[n_words] = pd.DataFrame(index=vocabulary, columns=list(method_list)).fillna(0)\n",
    "\n",
    "    for method, words_dict in files.items():\n",
    "        for n_words, info in words_dict.items():\n",
    "            df_dict[n_words].loc[info['selected_vocabulary'], method] = 1\n",
    "    return df_dict\n",
    "\n",
    "def get_cross_jaccard_score(df):\n",
    "    methods = df.columns.tolist()\n",
    "    jaccard_df = pd.DataFrame(index=methods, columns=methods)\n",
    "    for method_1 in methods:\n",
    "        for method_2 in methods:\n",
    "            jaccard_df.loc[method_1, method_2] = jaccard_score(df[method_1], df[method_2])\n",
    "    return jaccard_df\n",
    "\n",
    "def get_similarity_metrics(df_dict):\n",
    "    correlations_dict = {}\n",
    "    jaccard_score_dict = {}\n",
    "    for n_words, df in df_dict.items():\n",
    "        df_filtered = df.loc[:,(df.sum(axis=0) != 0).values] # remove lfs (or other methods) when they have no values\n",
    "        correlations_dict[n_words] = df_filtered.corr() \n",
    "        jaccard_score_dict[n_words] = get_cross_jaccard_score(df_filtered)\n",
    "    \n",
    "    return correlations_dict, jaccard_score_dict\n",
    "\n",
    "def compare_shap_over_n_words_set_similarity(df_dict: dict, n_words_list, method_list):\n",
    "    df_comp = pd.DataFrame(columns=method_list, index=n_words_list)\n",
    "    for n_words, df in df_dict.items():\n",
    "        cols = df.columns\n",
    "        df_comp.loc[n_words, cols] = df['shap'][cols]\n",
    "    df_comp.index = df_comp.index.astype('int')\n",
    "    df_comp = df_comp.sort_index()\n",
    "    df_comp = df_comp.drop(columns=['shap'])\n",
    "    return df_comp\n",
    "\n",
    "def compare_performance_over_n_words_enron(files, n_words_list, method_list, baseline=None):\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    cols = []\n",
    "    for method in method_list:\n",
    "        for metric in metrics:\n",
    "            cols.append((method, metric))\n",
    "    df_metrics = pd.DataFrame(columns=pd.MultiIndex.from_tuples(cols), index=n_words_list)\n",
    "\n",
    "    for method, words_dict in files.items():\n",
    "        for n_words, info in words_dict.items():\n",
    "            for metric in metrics:\n",
    "                df_metrics.loc[n_words, (method, metric)] = info['classification_report_test']['1.0'][metric]\n",
    "    if baseline is not None:\n",
    "        for n_words in n_words_list:\n",
    "            for metric in metrics:\n",
    "                df_metrics.loc[n_words, ('baseline',metric)] = baseline['1.0'][metric]\n",
    "    \n",
    "    df_metrics.index = df_metrics.index.astype('int')\n",
    "    df_metrics = df_metrics.sort_index()\n",
    "    return df_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, method_list, n_words_list = get_extractor_timings(files)\n",
    "df.to_csv('../results/tables/mit_bih_n_features_timings.csv', sep=';')\n",
    "plot_extractors_timings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = get_selected_words_per_extractor_per_n_words(files, vocabulary, n_words_list, method_list)\n",
    "correlations_dict, jaccard_score_dict = get_similarity_metrics(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_correlations = compare_shap_over_n_words_set_similarity(correlations_dict, n_words_list, method_list)\n",
    "shap_jaccard = compare_shap_over_n_words_set_similarity(jaccard_score_dict, n_words_list, method_list)\n",
    "shap_correlations.to_csv('../results/tables/mit_bih_correlations.csv', sep=';')\n",
    "shap_jaccard.to_csv('../results/tables/mit_bih_jaccard.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/mit_bih_baseline.json', 'r') as file:\n",
    "    baseline_mit_bih = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = compare_performance_over_n_words_enron(files, n_words_list, method_list, baseline=baseline_mit_bih['classification_report_test']).iloc[:-1]\n",
    "df_metrics.to_csv('../results/tables/mit_bih_performance.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">lfs</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mutual_information</th>\n",
       "      <th colspan=\"3\" halign=\"left\">shap</th>\n",
       "      <th colspan=\"3\" halign=\"left\">f_val</th>\n",
       "      <th colspan=\"3\" halign=\"left\">baseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.755747</td>\n",
       "      <td>0.862295</td>\n",
       "      <td>0.805513</td>\n",
       "      <td>0.921233</td>\n",
       "      <td>0.881967</td>\n",
       "      <td>0.901173</td>\n",
       "      <td>0.840237</td>\n",
       "      <td>0.931148</td>\n",
       "      <td>0.883359</td>\n",
       "      <td>0.808442</td>\n",
       "      <td>0.816393</td>\n",
       "      <td>0.812398</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.792793</td>\n",
       "      <td>0.865574</td>\n",
       "      <td>0.827586</td>\n",
       "      <td>0.901899</td>\n",
       "      <td>0.934426</td>\n",
       "      <td>0.917874</td>\n",
       "      <td>0.906752</td>\n",
       "      <td>0.92459</td>\n",
       "      <td>0.915584</td>\n",
       "      <td>0.831169</td>\n",
       "      <td>0.839344</td>\n",
       "      <td>0.835237</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.822857</td>\n",
       "      <td>0.944262</td>\n",
       "      <td>0.879389</td>\n",
       "      <td>0.891566</td>\n",
       "      <td>0.970492</td>\n",
       "      <td>0.929356</td>\n",
       "      <td>0.905956</td>\n",
       "      <td>0.947541</td>\n",
       "      <td>0.926282</td>\n",
       "      <td>0.86478</td>\n",
       "      <td>0.901639</td>\n",
       "      <td>0.882825</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.863905</td>\n",
       "      <td>0.957377</td>\n",
       "      <td>0.908243</td>\n",
       "      <td>0.846377</td>\n",
       "      <td>0.957377</td>\n",
       "      <td>0.898462</td>\n",
       "      <td>0.915094</td>\n",
       "      <td>0.954098</td>\n",
       "      <td>0.934189</td>\n",
       "      <td>0.87988</td>\n",
       "      <td>0.960656</td>\n",
       "      <td>0.918495</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>0.855072</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.907692</td>\n",
       "      <td>0.829609</td>\n",
       "      <td>0.97377</td>\n",
       "      <td>0.895928</td>\n",
       "      <td>0.902141</td>\n",
       "      <td>0.967213</td>\n",
       "      <td>0.933544</td>\n",
       "      <td>0.839888</td>\n",
       "      <td>0.980328</td>\n",
       "      <td>0.90469</td>\n",
       "      <td>0.845481</td>\n",
       "      <td>0.95082</td>\n",
       "      <td>0.895062</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         lfs                     mutual_information                      \\\n",
       "   precision    recall  f1-score          precision    recall  f1-score   \n",
       "2   0.755747  0.862295  0.805513           0.921233  0.881967  0.901173   \n",
       "3   0.792793  0.865574  0.827586           0.901899  0.934426  0.917874   \n",
       "5   0.822857  0.944262  0.879389           0.891566  0.970492  0.929356   \n",
       "10  0.863905  0.957377  0.908243           0.846377  0.957377  0.898462   \n",
       "15  0.855072  0.967213  0.907692           0.829609   0.97377  0.895928   \n",
       "\n",
       "        shap                         f_val                      baseline  \\\n",
       "   precision    recall  f1-score precision    recall  f1-score precision   \n",
       "2   0.840237  0.931148  0.883359  0.808442  0.816393  0.812398  0.845481   \n",
       "3   0.906752   0.92459  0.915584  0.831169  0.839344  0.835237  0.845481   \n",
       "5   0.905956  0.947541  0.926282   0.86478  0.901639  0.882825  0.845481   \n",
       "10  0.915094  0.954098  0.934189   0.87988  0.960656  0.918495  0.845481   \n",
       "15  0.902141  0.967213  0.933544  0.839888  0.980328   0.90469  0.845481   \n",
       "\n",
       "                       \n",
       "     recall  f1-score  \n",
       "2   0.95082  0.895062  \n",
       "3   0.95082  0.895062  \n",
       "5   0.95082  0.895062  \n",
       "10  0.95082  0.895062  \n",
       "15  0.95082  0.895062  "
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
