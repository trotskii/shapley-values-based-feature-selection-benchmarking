{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np \n",
    "import sklearn.feature_extraction.text as ft \n",
    "from sklearn.preprocessing import minmax_scale\n",
    "import nltk\n",
    "import sys \n",
    "from tqdm.notebook import tqdm\n",
    "from scipy.stats import entropy\n",
    "from sklearn.model_selection import train_test_split, cross_val_score\n",
    "from scipy.sparse import csr_matrix, csc_matrix\n",
    "from sklearn.feature_selection import SequentialFeatureSelector\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "from sklearn.metrics import balanced_accuracy_score\n",
    "from sklearn.base import clone\n",
    "import sklearn \n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer, TfidfTransformer\n",
    "\n",
    "from timeit import default_timer as timer\n",
    "from datetime import timedelta\n",
    "import logging\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "from src.preprocessing.ctfidf import CTFIDFVectorizer\n",
    "import src.preprocessing.text_preprocessing as tp\n",
    "import src.preprocessing.feature_extraction.text.filtering as filter\n",
    "import src.preprocessing.feature_extraction.text.wrapping as wrapping\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "tqdm.pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def record_results(model: sklearn.base.BaseEstimator, X_t, y_t, X_val, y_val, timing: dict) -> dict:\n",
    "    \"\"\"\n",
    "    Evaluates the passed model both on test and train set and returns a dict with evaluation results.\n",
    "    Arguments:\n",
    "        model - trained sklearn model to evaluate\n",
    "        X_t - training features\n",
    "        y_t - training labels\n",
    "        X_val - testing features\n",
    "        y_val - testing labels\n",
    "        timing - dict with timings to add inference timings to\n",
    "    Retruns:\n",
    "        results - dict with all evaluation results\n",
    "    \"\"\"\n",
    "\n",
    "    predictions_train = model.predict(X_t)\n",
    "\n",
    "    start = timer()\n",
    "    predictions_test = model.predict(X_val)\n",
    "    end = timer()\n",
    "    timing['model_inference_time'] = str(timedelta(seconds=end-start))\n",
    "    logging.info('Model inference finished.')\n",
    "\n",
    "    report_train = classification_report(y_t, predictions_train, output_dict=True)\n",
    "    report_test = classification_report(y_val, predictions_test, output_dict=True)\n",
    "\n",
    "    cm_train = confusion_matrix(y_t, predictions_train, normalize='true')\n",
    "    cm_test = confusion_matrix(y_val, predictions_test, normalize='true')\n",
    "\n",
    "    results = {}\n",
    "    results['timing'] = timing\n",
    "    results['training_data_samples'] = X_t.shape[0]\n",
    "    results['test_data_samples'] = X_val.shape[0]\n",
    "    results['classification_report_train'] = report_train\n",
    "    results['classification_report_test'] = report_test\n",
    "    results['confustion_matrix_train'] = cm_train.tolist()\n",
    "    results['confusion_matrix_test'] = cm_test.tolist()\n",
    "    results['model_type'] = type(model).__name__\n",
    "    results['model_params'] = model.get_params()\n",
    "\n",
    "    return results\n",
    "\n",
    "def test_extractor(model: sklearn.base.BaseEstimator, extractor: filter.BaseTextFeatureExtractor, df: pd.DataFrame, split: float, n_words: int) -> dict:\n",
    "    \"\"\"\n",
    "    Train passed model on a features selected by passed extractor.\n",
    "    \"\"\"\n",
    "    timing = {}\n",
    "    X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'], test_size=split, stratify=df['Label'])\n",
    "\n",
    "    count_vectorizer = CountVectorizer(binary=True)\n",
    "    count_vectorizer.fit(X_train)\n",
    "\n",
    "    X_train_vectorized = count_vectorizer.transform(X_train)\n",
    "    X_test_vectorized = count_vectorizer.transform(X_test)\n",
    "\n",
    "    start = timer()\n",
    "    extractor.fit(X_train_vectorized, y_train)\n",
    "    end = timer()\n",
    "    timing['extractor_fit'] = str(timedelta(seconds=end-start))\n",
    "    logging.info('Fit extractor.')\n",
    "    \n",
    "    start = timer()\n",
    "    vocabulary = count_vectorizer.get_feature_names_out()\n",
    "    X_train_vectorized_filtered, vocabulary_filtered = extractor.filter_n_best(X_train_vectorized, n_words, vocabulary)\n",
    "    X_test_vectorized_filtered, _ = extractor.filter_n_best(X_test_vectorized, n_words, vocabulary)\n",
    "    end = timer()\n",
    "    timing['filtered_features'] = str(timedelta(seconds=end-start))\n",
    "\n",
    "\n",
    "    tfidf = TfidfTransformer()\n",
    "    X_train_vectorized_filtered = tfidf.fit_transform(X_train_vectorized_filtered, y_train)\n",
    "    X_test_vectorized_filtered = tfidf.transform(X_test_vectorized_filtered)\n",
    "\n",
    "    start = timer()\n",
    "    model.fit(X_train_vectorized_filtered, y_train)\n",
    "    end = timer()    \n",
    "    timing['model_training_time'] = str(timedelta(seconds=end-start))\n",
    "    logging.info('Model training finished.')\n",
    "\n",
    "    results = record_results(model=model, \n",
    "                                X_t=X_train_vectorized_filtered,\n",
    "                                y_t=y_train,\n",
    "                                X_val=X_test_vectorized_filtered,\n",
    "                                y_val=y_test,\n",
    "                                timing=timing)\n",
    "    results['n_words'] = n_words\n",
    "    results['selected_vocabulary'] = vocabulary_filtered.tolist()\n",
    "\n",
    "    return results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9444f35d2a244f0e8b06814e44be2d2b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/5958 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv('../data/brown_corpus/brown_corpus.csv', sep=';')\n",
    "df = df.fillna('')\n",
    "df = df.astype('str')\n",
    "\n",
    "# df = df.loc[~df['Label'].isin(['humor', 'religion', 'reviews', 'science_fiction'])]\n",
    "df['Label'] = df['Label'].astype('category')\n",
    "df['Label'] = df['Label'].cat.codes\n",
    "df['Text'] = df['Text'].progress_apply(tp.normalize_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 196,
   "metadata": {},
   "outputs": [],
   "source": [
    "extractor = filter.TermStrengthFeatureExtractor()\n",
    "model = OneVsRestClassifier(SVC(class_weight='balanced', kernel='rbf', gamma=1/10))\n",
    "# results = test_extractor(model, extractor, df, 0.3, n_words=10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "timing = {}\n",
    "X_train, X_test, y_train, y_test = train_test_split(df['Text'], df['Label'], test_size=0.3)\n",
    "\n",
    "count_vectorizer = CountVectorizer(binary=True)\n",
    "count_vectorizer.fit(X_train)\n",
    "\n",
    "X_train_vectorized = count_vectorizer.transform(X_train)\n",
    "X_test_vectorized = count_vectorizer.transform(X_test)\n",
    "\n",
    "vocabulary = count_vectorizer.get_feature_names_out()\n",
    "extractor = wrapping.ShapFeatureExtractor(vocabulary=vocabulary)\n",
    "\n",
    "start = timer()\n",
    "extractor.fit(X_train_vectorized, y_train)\n",
    "end = timer()\n",
    "timing['extractor_fit'] = str(timedelta(seconds=end-start))\n",
    "logging.info('Fit extractor.')\n",
    "\n",
    "# start = timer()\n",
    "# X_train_vectorized_filtered, vocabulary_filtered = extractor.filter_n_best(X_train_vectorized, n_words)\n",
    "# X_test_vectorized_filtered, _ = extractor.filter_n_best(X_test_vectorized, n_words)\n",
    "# end = timer()\n",
    "# timing['filtered_features'] = str(timedelta(seconds=end-start))\n",
    "\n",
    "# start = timer()\n",
    "# model.fit(X_train_vectorized_filtered, y_train)\n",
    "# end = timer()    \n",
    "# timing['model_training_time'] = str(timedelta(seconds=end-start))\n",
    "# logging.info('Model training finished.')\n",
    "\n",
    "# results = record_results(model=model, \n",
    "#                             X_t=X_train_vectorized_filtered,\n",
    "#                             y_t=y_train,\n",
    "#                             X_val=X_test_vectorized_filtered,\n",
    "#                             y_val=y_test,\n",
    "#                             timing=timing)\n",
    "# results['n_words'] = n_words\n",
    "# results['selected_vocabulary'] = vocabulary_filtered.tolist()\n",
    "\n",
    "# return results\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1251, 30713)"
      ]
     },
     "execution_count": 201,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "extractor.feature_strength_metric.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_values = extractor.shap_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [],
   "source": [
    "t_l = []\n",
    "for cls in shap_values:\n",
    "    t_l.append(np.mean(np.abs(cls), axis=0))\n",
    "arr = np.vstack(t_l)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [],
   "source": [
    "t = np.maximum.reduce(arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.0"
      ]
     },
     "execution_count": 219,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.min(t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (main, Jan 15 2022, 11:48:00) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
