{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import sys \n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.feature_extraction.text as ft \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "import src.preprocessing.text_preprocessing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'enron'\n",
    "base_path = '../results/'\n",
    "path = f'{base_path}{FOLDER}/'\n",
    "full_paths = [f'{path}{file}' for file in os.listdir(path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "for p in full_paths:\n",
    "    name = p.split('/')[-1]\n",
    "    split = name.split('_')\n",
    "    method = '_'.join(split[1:-1])\n",
    "    n_words = split[-1].split('.')[0]\n",
    "    with open(p, 'r') as file:\n",
    "        if method not in files:\n",
    "            files[method] = {}\n",
    "        files[method][n_words] = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "85828a616ef247dab2643d9b5144ec44",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df = pd.read_csv('../data/enron/enron_spam_data.csv', sep=',')\n",
    "df = df.fillna('')\n",
    "df = df.astype('str')\n",
    "df['Text'] = df.apply(lambda x: x['Subject'] + ', ' + x['Message'], axis=1)\n",
    "df['Label'] = np.where(df['Spam/Ham'].values == 'ham', 0, 1)\n",
    "df['Text'] = df['Text'].progress_apply(tp.normalize_text)\n",
    "\n",
    "count_vectorizer = ft.CountVectorizer()\n",
    "count_vectorizer.fit(df['Text'])\n",
    "vocabulary = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractor_timings(files: dict) -> pd.DataFrame:\n",
    "    methods = files.keys()\n",
    "    df = pd.DataFrame(columns=methods)\n",
    "    n_words_list = set()\n",
    "    method_list = set()\n",
    "    for method, words_dict in files.items():\n",
    "        method_list.add(method)\n",
    "        for n_words, info in words_dict.items():\n",
    "                df.loc[n_words, method] = info['timing']['extractor_fit']\n",
    "                n_words_list.add(n_words)\n",
    "                \n",
    "    df.index = df.index.astype('int')\n",
    "    df = df.sort_index()\n",
    "    df = df.apply(pd.to_timedelta)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].dt.total_seconds()\n",
    "    return df, method_list, n_words_list\n",
    "\n",
    "def plot_extractors_timings(df) -> plt.figure:\n",
    "    axes = df.plot(logy=True, logx=True, figsize=(16, 10))\n",
    "    axes.set_xlabel('# selected words')\n",
    "    axes.set_ylabel('runtime (sec)')\n",
    "    axes.set_label('runtime (sec)')\n",
    "    plt.title('Feature extractor runtimes vs number of the selected words.')\n",
    "    plt.savefig('../figures/enron_extractor_runtime_vs_n_words.png')\n",
    "    plt.close()\n",
    "\n",
    "def get_selected_words_per_extractor_per_n_words(files: dict, vocabulary, n_words_list, method_list):\n",
    "    df_dict = {}\n",
    "\n",
    "    for n_words in n_words_list:\n",
    "        df_dict[n_words] = pd.DataFrame(index=vocabulary, columns=list(method_list)).fillna(0)\n",
    "\n",
    "    for method, words_dict in files.items():\n",
    "        for n_words, info in words_dict.items():\n",
    "            df_dict[n_words].loc[info['selected_vocabulary'], method] = 1\n",
    "    return df_dict\n",
    "\n",
    "def get_cross_jaccard_score(df):\n",
    "    methods = df.columns.tolist()\n",
    "    jaccard_df = pd.DataFrame(index=methods, columns=methods)\n",
    "    for method_1 in methods:\n",
    "        for method_2 in methods:\n",
    "            jaccard_df.loc[method_1, method_2] = jaccard_score(df[method_1], df[method_2])\n",
    "    return jaccard_df\n",
    "\n",
    "def get_similarity_metrics(df_dict):\n",
    "    correlations_dict = {}\n",
    "    jaccard_score_dict = {}\n",
    "    for n_words, df in df_dict.items():\n",
    "        df_filtered = df.loc[:,(df.sum(axis=0) != 0).values] # remove lfs (or other methods) when they have no values\n",
    "        correlations_dict[n_words] = df_filtered.corr() \n",
    "        jaccard_score_dict[n_words] = get_cross_jaccard_score(df_filtered)\n",
    "    \n",
    "    return correlations_dict, jaccard_score_dict\n",
    "\n",
    "def compare_shap_over_n_words_set_similarity(df_dict: dict, n_words_list, method_list):\n",
    "    df_comp = pd.DataFrame(columns=method_list, index=n_words_list)\n",
    "    for n_words, df in df_dict.items():\n",
    "        cols = df.columns\n",
    "        df_comp.loc[n_words, cols] = df['shap'][cols]\n",
    "    df_comp.index = df_comp.index.astype('int')\n",
    "    df_comp = df_comp.sort_index()\n",
    "    df_comp = df_comp.drop(columns=['shap'])\n",
    "    return df_comp\n",
    "\n",
    "def compare_performance_over_n_words_enron(files, n_words_list, method_list):\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    cols = []\n",
    "    for method in method_list:\n",
    "        for metric in metrics:\n",
    "            cols.append((method, metric))\n",
    "    df_metrics = pd.DataFrame(columns=pd.MultiIndex.from_tuples(cols), index=n_words_list)\n",
    "\n",
    "    for method, words_dict in files.items():\n",
    "        for n_words, info in words_dict.items():\n",
    "            for metric in metrics:\n",
    "                df_metrics.loc[n_words, (method, metric)] = info['classification_report_test']['1'][metric]\n",
    "    \n",
    "    df_metrics.index = df_metrics.index.astype('int')\n",
    "    df_metrics = df_metrics.sort_index()\n",
    "    return df_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, method_list, n_words_list = get_extractor_timings(files)\n",
    "plot_extractors_timings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = get_selected_words_per_extractor_per_n_words(files, vocabulary, n_words_list, method_list)\n",
    "correlations_dict, jaccard_score_dict = get_similarity_metrics(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_correlations = compare_shap_over_n_words_set_similarity(correlations_dict, n_words_list, method_list)\n",
    "shap_jaccard = compare_shap_over_n_words_set_similarity(jaccard_score_dict, n_words_list, method_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = compare_performance_over_n_words_enron(files, n_words_list, method_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">term_strength</th>\n",
       "      <th colspan=\"3\" halign=\"left\">eccd</th>\n",
       "      <th colspan=\"3\" halign=\"left\">shap</th>\n",
       "      <th>trl</th>\n",
       "      <th>...</th>\n",
       "      <th>linear_measure_5</th>\n",
       "      <th colspan=\"3\" halign=\"left\">mutual_information</th>\n",
       "      <th colspan=\"3\" halign=\"left\">chi2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tfidf</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.653981</td>\n",
       "      <td>0.759744</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.744748</td>\n",
       "      <td>0.976858</td>\n",
       "      <td>0.845157</td>\n",
       "      <td>0.840322</td>\n",
       "      <td>0.921833</td>\n",
       "      <td>0.879192</td>\n",
       "      <td>0.649051</td>\n",
       "      <td>...</td>\n",
       "      <td>0.709567</td>\n",
       "      <td>0.755491</td>\n",
       "      <td>0.93042</td>\n",
       "      <td>0.83388</td>\n",
       "      <td>0.751019</td>\n",
       "      <td>0.937146</td>\n",
       "      <td>0.833822</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>0.899003</td>\n",
       "      <td>0.788519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.894914</td>\n",
       "      <td>0.951566</td>\n",
       "      <td>0.922371</td>\n",
       "      <td>0.915214</td>\n",
       "      <td>0.958</td>\n",
       "      <td>0.936118</td>\n",
       "      <td>0.932077</td>\n",
       "      <td>0.977095</td>\n",
       "      <td>0.954056</td>\n",
       "      <td>0.718275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.92125</td>\n",
       "      <td>0.912372</td>\n",
       "      <td>0.974195</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.912753</td>\n",
       "      <td>0.96931</td>\n",
       "      <td>0.940182</td>\n",
       "      <td>0.883897</td>\n",
       "      <td>0.965277</td>\n",
       "      <td>0.922797</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.922246</td>\n",
       "      <td>0.976129</td>\n",
       "      <td>0.948423</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>0.980177</td>\n",
       "      <td>0.958423</td>\n",
       "      <td>0.943517</td>\n",
       "      <td>0.984167</td>\n",
       "      <td>0.963413</td>\n",
       "      <td>0.72208</td>\n",
       "      <td>...</td>\n",
       "      <td>0.951467</td>\n",
       "      <td>0.944601</td>\n",
       "      <td>0.985178</td>\n",
       "      <td>0.964463</td>\n",
       "      <td>0.946201</td>\n",
       "      <td>0.983851</td>\n",
       "      <td>0.964659</td>\n",
       "      <td>0.917489</td>\n",
       "      <td>0.969316</td>\n",
       "      <td>0.942691</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.943976</td>\n",
       "      <td>0.987348</td>\n",
       "      <td>0.965175</td>\n",
       "      <td>0.947718</td>\n",
       "      <td>0.985267</td>\n",
       "      <td>0.966128</td>\n",
       "      <td>0.95511</td>\n",
       "      <td>0.989976</td>\n",
       "      <td>0.97223</td>\n",
       "      <td>0.720287</td>\n",
       "      <td>...</td>\n",
       "      <td>0.963017</td>\n",
       "      <td>0.955897</td>\n",
       "      <td>0.989028</td>\n",
       "      <td>0.97218</td>\n",
       "      <td>0.951466</td>\n",
       "      <td>0.990464</td>\n",
       "      <td>0.970574</td>\n",
       "      <td>0.937942</td>\n",
       "      <td>0.979992</td>\n",
       "      <td>0.958506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.954633</td>\n",
       "      <td>0.990899</td>\n",
       "      <td>0.972428</td>\n",
       "      <td>0.957006</td>\n",
       "      <td>0.991457</td>\n",
       "      <td>0.973927</td>\n",
       "      <td>0.967176</td>\n",
       "      <td>0.992286</td>\n",
       "      <td>0.97957</td>\n",
       "      <td>0.731114</td>\n",
       "      <td>...</td>\n",
       "      <td>0.974574</td>\n",
       "      <td>0.963023</td>\n",
       "      <td>0.99327</td>\n",
       "      <td>0.977912</td>\n",
       "      <td>0.960878</td>\n",
       "      <td>0.992171</td>\n",
       "      <td>0.976273</td>\n",
       "      <td>0.947592</td>\n",
       "      <td>0.987951</td>\n",
       "      <td>0.967351</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.963423</td>\n",
       "      <td>0.993588</td>\n",
       "      <td>0.978273</td>\n",
       "      <td>0.96326</td>\n",
       "      <td>0.992496</td>\n",
       "      <td>0.977659</td>\n",
       "      <td>0.963837</td>\n",
       "      <td>0.992947</td>\n",
       "      <td>0.978176</td>\n",
       "      <td>0.715983</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97833</td>\n",
       "      <td>0.964529</td>\n",
       "      <td>0.993742</td>\n",
       "      <td>0.978918</td>\n",
       "      <td>0.964487</td>\n",
       "      <td>0.992871</td>\n",
       "      <td>0.978473</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.988411</td>\n",
       "      <td>0.973557</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.965487</td>\n",
       "      <td>0.993131</td>\n",
       "      <td>0.979114</td>\n",
       "      <td>0.962799</td>\n",
       "      <td>0.993919</td>\n",
       "      <td>0.978111</td>\n",
       "      <td>0.964364</td>\n",
       "      <td>0.993589</td>\n",
       "      <td>0.978758</td>\n",
       "      <td>0.780547</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979067</td>\n",
       "      <td>0.96803</td>\n",
       "      <td>0.993471</td>\n",
       "      <td>0.980586</td>\n",
       "      <td>0.968674</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.980531</td>\n",
       "      <td>0.962524</td>\n",
       "      <td>0.98727</td>\n",
       "      <td>0.97474</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.993112</td>\n",
       "      <td>0.979617</td>\n",
       "      <td>0.964064</td>\n",
       "      <td>0.994088</td>\n",
       "      <td>0.978846</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.99482</td>\n",
       "      <td>0.977223</td>\n",
       "      <td>0.787528</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975752</td>\n",
       "      <td>0.969464</td>\n",
       "      <td>0.993625</td>\n",
       "      <td>0.981396</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.979067</td>\n",
       "      <td>0.956845</td>\n",
       "      <td>0.994011</td>\n",
       "      <td>0.975074</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.959505</td>\n",
       "      <td>0.99608</td>\n",
       "      <td>0.97745</td>\n",
       "      <td>0.96275</td>\n",
       "      <td>0.993893</td>\n",
       "      <td>0.978074</td>\n",
       "      <td>0.960032</td>\n",
       "      <td>0.994313</td>\n",
       "      <td>0.976872</td>\n",
       "      <td>0.800334</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975393</td>\n",
       "      <td>0.961075</td>\n",
       "      <td>0.994684</td>\n",
       "      <td>0.977591</td>\n",
       "      <td>0.961871</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.978253</td>\n",
       "      <td>0.955449</td>\n",
       "      <td>0.993772</td>\n",
       "      <td>0.974234</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>0.954952</td>\n",
       "      <td>0.995338</td>\n",
       "      <td>0.974727</td>\n",
       "      <td>0.958507</td>\n",
       "      <td>0.994938</td>\n",
       "      <td>0.976382</td>\n",
       "      <td>0.959434</td>\n",
       "      <td>0.99329</td>\n",
       "      <td>0.976068</td>\n",
       "      <td>0.811655</td>\n",
       "      <td>...</td>\n",
       "      <td>0.975449</td>\n",
       "      <td>0.964656</td>\n",
       "      <td>0.995689</td>\n",
       "      <td>0.979927</td>\n",
       "      <td>0.958888</td>\n",
       "      <td>0.99611</td>\n",
       "      <td>0.977144</td>\n",
       "      <td>0.955148</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.974513</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0.952577</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.973775</td>\n",
       "      <td>0.960269</td>\n",
       "      <td>0.993865</td>\n",
       "      <td>0.976778</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.99508</td>\n",
       "      <td>0.976474</td>\n",
       "      <td>0.901283</td>\n",
       "      <td>...</td>\n",
       "      <td>0.972955</td>\n",
       "      <td>0.957554</td>\n",
       "      <td>0.995776</td>\n",
       "      <td>0.976291</td>\n",
       "      <td>0.957438</td>\n",
       "      <td>0.996344</td>\n",
       "      <td>0.976504</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>0.993811</td>\n",
       "      <td>0.969682</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 27 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      term_strength                          eccd                      \\\n",
       "          precision    recall  f1-score precision    recall  f1-score   \n",
       "10         0.653981  0.759744  0.702906  0.744748  0.976858  0.845157   \n",
       "50         0.894914  0.951566  0.922371  0.915214     0.958  0.936118   \n",
       "100        0.922246  0.976129  0.948423  0.937615  0.980177  0.958423   \n",
       "200        0.943976  0.987348  0.965175  0.947718  0.985267  0.966128   \n",
       "500        0.954633  0.990899  0.972428  0.957006  0.991457  0.973927   \n",
       "1000       0.963423  0.993588  0.978273   0.96326  0.992496  0.977659   \n",
       "3000       0.965487  0.993131  0.979114  0.962799  0.993919  0.978111   \n",
       "5000       0.966484  0.993112  0.979617  0.964064  0.994088  0.978846   \n",
       "10000      0.959505   0.99608   0.97745   0.96275  0.993893  0.978074   \n",
       "15000      0.954952  0.995338  0.974727  0.958507  0.994938  0.976382   \n",
       "25000      0.952577  0.995937  0.973775  0.960269  0.993865  0.976778   \n",
       "\n",
       "           shap                           trl  ... linear_measure_5  \\\n",
       "      precision    recall  f1-score precision  ...         f1-score   \n",
       "10     0.840322  0.921833  0.879192  0.649051  ...         0.709567   \n",
       "50     0.932077  0.977095  0.954056  0.718275  ...          0.92125   \n",
       "100    0.943517  0.984167  0.963413   0.72208  ...         0.951467   \n",
       "200     0.95511  0.989976   0.97223  0.720287  ...         0.963017   \n",
       "500    0.967176  0.992286   0.97957  0.731114  ...         0.974574   \n",
       "1000   0.963837  0.992947  0.978176  0.715983  ...          0.97833   \n",
       "3000   0.964364  0.993589  0.978758  0.780547  ...         0.979067   \n",
       "5000   0.960239   0.99482  0.977223  0.787528  ...         0.975752   \n",
       "10000  0.960032  0.994313  0.976872  0.800334  ...         0.975393   \n",
       "15000  0.959434   0.99329  0.976068  0.811655  ...         0.975449   \n",
       "25000  0.958551   0.99508  0.976474  0.901283  ...         0.972955   \n",
       "\n",
       "      mutual_information                          chi2                      \\\n",
       "               precision    recall  f1-score precision    recall  f1-score   \n",
       "10              0.755491   0.93042   0.83388  0.751019  0.937146  0.833822   \n",
       "50              0.912372  0.974195  0.942271  0.912753   0.96931  0.940182   \n",
       "100             0.944601  0.985178  0.964463  0.946201  0.983851  0.964659   \n",
       "200             0.955897  0.989028   0.97218  0.951466  0.990464  0.970574   \n",
       "500             0.963023   0.99327  0.977912  0.960878  0.992171  0.976273   \n",
       "1000            0.964529  0.993742  0.978918  0.964487  0.992871  0.978473   \n",
       "3000             0.96803  0.993471  0.980586  0.968674  0.992681  0.980531   \n",
       "5000            0.969464  0.993625  0.981396  0.966375  0.992098  0.979067   \n",
       "10000           0.961075  0.994684  0.977591  0.961871  0.995203  0.978253   \n",
       "15000           0.964656  0.995689  0.979927  0.958888   0.99611  0.977144   \n",
       "25000           0.957554  0.995776  0.976291  0.957438  0.996344  0.976504   \n",
       "\n",
       "          tfidf                      \n",
       "      precision    recall  f1-score  \n",
       "10     0.702219  0.899003  0.788519  \n",
       "50     0.883897  0.965277  0.922797  \n",
       "100    0.917489  0.969316  0.942691  \n",
       "200    0.937942  0.979992  0.958506  \n",
       "500    0.947592  0.987951  0.967351  \n",
       "1000   0.959142  0.988411  0.973557  \n",
       "3000   0.962524   0.98727   0.97474  \n",
       "5000   0.956845  0.994011  0.975074  \n",
       "10000  0.955449  0.993772  0.974234  \n",
       "15000  0.955148  0.994681  0.974513  \n",
       "25000  0.946697  0.993811  0.969682  \n",
       "\n",
       "[11 rows x 27 columns]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
