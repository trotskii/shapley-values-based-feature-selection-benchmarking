{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json \n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import numpy as np\n",
    "from sklearn.metrics import jaccard_score\n",
    "import sys \n",
    "from tqdm.notebook import tqdm\n",
    "import sklearn.feature_extraction.text as ft \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, '../')\n",
    "import src.preprocessing.text_preprocessing as tp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcParams['text.usetex'] = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDER = 'enron'\n",
    "base_path = '../results/'\n",
    "path = f'{base_path}{FOLDER}/'\n",
    "full_paths = [f'{path}{file}' for file in os.listdir(path)]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "files = {}\n",
    "for p in full_paths:\n",
    "    name = p.split('/')[-1]\n",
    "    split = name.split('_')\n",
    "    method = '_'.join(split[1:-1])\n",
    "    n_words = split[-1].split('.')[0]\n",
    "    with open(p, 'r') as file:\n",
    "        if method not in files:\n",
    "            files[method] = {}\n",
    "        files[method][n_words] = json.load(file)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "99374dbf082f4dd596a9c15455ff15b0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/33716 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tqdm.pandas()\n",
    "df = pd.read_csv('../data/enron/enron_spam_data.csv', sep=',')\n",
    "df = df.fillna('')\n",
    "df = df.astype('str')\n",
    "df['Text'] = df.apply(lambda x: x['Subject'] + ', ' + x['Message'], axis=1)\n",
    "df['Label'] = np.where(df['Spam/Ham'].values == 'ham', 0, 1)\n",
    "df['Text'] = df['Text'].progress_apply(tp.normalize_text)\n",
    "\n",
    "count_vectorizer = ft.CountVectorizer()\n",
    "count_vectorizer.fit(df['Text'])\n",
    "vocabulary = count_vectorizer.get_feature_names_out()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_extractor_timings(files: dict) -> pd.DataFrame:\n",
    "    methods = files.keys()\n",
    "    df = pd.DataFrame(columns=methods)\n",
    "    n_words_list = set()\n",
    "    method_list = set()\n",
    "    for method, words_dict in files.items():\n",
    "        method_list.add(method)\n",
    "        for n_words, info in words_dict.items():\n",
    "                df.loc[n_words, method] = info['timing']['extractor_fit']\n",
    "                n_words_list.add(n_words)\n",
    "                \n",
    "    df.index = df.index.astype('int')\n",
    "    df = df.sort_index()\n",
    "    df = df.apply(pd.to_timedelta)\n",
    "    for col in df.columns:\n",
    "        df[col] = df[col].dt.total_seconds()\n",
    "    return df, method_list, n_words_list\n",
    "\n",
    "def plot_extractors_timings(df) -> plt.figure:\n",
    "    axes = df.plot(logy=True, logx=True, figsize=(16, 10))\n",
    "    axes.set_xlabel('# selected words')\n",
    "    axes.set_ylabel('runtime (sec)')\n",
    "    axes.set_label('runtime (sec)')\n",
    "    plt.title('Feature extractor runtimes vs number of the selected words.')\n",
    "    plt.savefig('../figures/enron_extractor_runtime_vs_n_words.png')\n",
    "    plt.close()\n",
    "\n",
    "def get_selected_words_per_extractor_per_n_words(files: dict, vocabulary, n_words_list, method_list):\n",
    "    df_dict = {}\n",
    "\n",
    "    for n_words in n_words_list:\n",
    "        df_dict[n_words] = pd.DataFrame(index=vocabulary, columns=list(method_list)).fillna(0)\n",
    "\n",
    "    for method, words_dict in files.items():\n",
    "        for n_words, info in words_dict.items():\n",
    "            df_dict[n_words].loc[info['selected_vocabulary'], method] = 1\n",
    "    return df_dict\n",
    "\n",
    "def get_cross_jaccard_score(df):\n",
    "    methods = df.columns.tolist()\n",
    "    jaccard_df = pd.DataFrame(index=methods, columns=methods)\n",
    "    for method_1 in methods:\n",
    "        for method_2 in methods:\n",
    "            jaccard_df.loc[method_1, method_2] = jaccard_score(df[method_1], df[method_2])\n",
    "    return jaccard_df\n",
    "\n",
    "def get_similarity_metrics(df_dict):\n",
    "    correlations_dict = {}\n",
    "    jaccard_score_dict = {}\n",
    "    for n_words, df in df_dict.items():\n",
    "        df_filtered = df.loc[:,(df.sum(axis=0) != 0).values] # remove lfs (or other methods) when they have no values\n",
    "        correlations_dict[n_words] = df_filtered.corr() \n",
    "        jaccard_score_dict[n_words] = get_cross_jaccard_score(df_filtered)\n",
    "    \n",
    "    return correlations_dict, jaccard_score_dict\n",
    "\n",
    "def compare_shap_over_n_words_set_similarity(df_dict: dict, n_words_list, method_list):\n",
    "    df_comp = pd.DataFrame(columns=method_list, index=n_words_list)\n",
    "    for n_words, df in df_dict.items():\n",
    "        cols = df.columns\n",
    "        df_comp.loc[n_words, cols] = df['shap'][cols]\n",
    "    df_comp.index = df_comp.index.astype('int')\n",
    "    df_comp = df_comp.sort_index()\n",
    "    df_comp = df_comp.drop(columns=['shap'])\n",
    "    return df_comp\n",
    "\n",
    "def compare_performance_over_n_words_enron(files, n_words_list, method_list, baseline=None):\n",
    "    metrics = ['precision', 'recall', 'f1-score']\n",
    "    cols = []\n",
    "    for method in method_list:\n",
    "        for metric in metrics:\n",
    "            cols.append((method, metric))\n",
    "    df_metrics = pd.DataFrame(columns=pd.MultiIndex.from_tuples(cols), index=n_words_list)\n",
    "\n",
    "    for method, words_dict in files.items():\n",
    "        for n_words, info in words_dict.items():\n",
    "            for metric in metrics:\n",
    "                df_metrics.loc[n_words, (method, metric)] = info['classification_report_test']['1'][metric]\n",
    "    if baseline is not None:\n",
    "        for n_words in n_words_list:\n",
    "            for metric in metrics:\n",
    "                df_metrics.loc[n_words, ('baseline',metric)] = baseline['1'][metric]\n",
    "    \n",
    "    df_metrics.index = df_metrics.index.astype('int')\n",
    "    df_metrics = df_metrics.sort_index()\n",
    "    return df_metrics\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "df, method_list, n_words_list = get_extractor_timings(files)\n",
    "df.to_csv('../results/tables/enron_n_word_timings.csv', sep=';')\n",
    "plot_extractors_timings(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dict = get_selected_words_per_extractor_per_n_words(files, vocabulary, n_words_list, method_list)\n",
    "correlations_dict, jaccard_score_dict = get_similarity_metrics(df_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "shap_correlations = compare_shap_over_n_words_set_similarity(correlations_dict, n_words_list, method_list)\n",
    "shap_jaccard = compare_shap_over_n_words_set_similarity(jaccard_score_dict, n_words_list, method_list)\n",
    "shap_correlations.to_csv('../results/tables/enron_correlations.csv', sep=';')\n",
    "shap_jaccard.to_csv('../results/tables/enron_jaccard.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('../results/enron_baseline.json', 'r') as file:\n",
    "    baseline_enron = json.load(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_metrics = compare_performance_over_n_words_enron(files, n_words_list, method_list, baseline=baseline_enron['classification_report_test'])\n",
    "df_metrics.to_csv('../results/tables/enron_performance.csv', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead tr th {\n",
       "        text-align: left;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th colspan=\"3\" halign=\"left\">term_strength</th>\n",
       "      <th colspan=\"3\" halign=\"left\">shap</th>\n",
       "      <th colspan=\"3\" halign=\"left\">linear_measure_5</th>\n",
       "      <th>eccd</th>\n",
       "      <th>...</th>\n",
       "      <th>mutual_information</th>\n",
       "      <th colspan=\"3\" halign=\"left\">chi2</th>\n",
       "      <th colspan=\"3\" halign=\"left\">tfidf</th>\n",
       "      <th colspan=\"3\" halign=\"left\">baseline</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th></th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>...</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "      <th>precision</th>\n",
       "      <th>recall</th>\n",
       "      <th>f1-score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>0.653981</td>\n",
       "      <td>0.759744</td>\n",
       "      <td>0.702906</td>\n",
       "      <td>0.840322</td>\n",
       "      <td>0.921833</td>\n",
       "      <td>0.879192</td>\n",
       "      <td>0.651361</td>\n",
       "      <td>0.779197</td>\n",
       "      <td>0.709567</td>\n",
       "      <td>0.744748</td>\n",
       "      <td>...</td>\n",
       "      <td>0.83388</td>\n",
       "      <td>0.751019</td>\n",
       "      <td>0.937146</td>\n",
       "      <td>0.833822</td>\n",
       "      <td>0.702219</td>\n",
       "      <td>0.899003</td>\n",
       "      <td>0.788519</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50</th>\n",
       "      <td>0.894914</td>\n",
       "      <td>0.951566</td>\n",
       "      <td>0.922371</td>\n",
       "      <td>0.932077</td>\n",
       "      <td>0.977095</td>\n",
       "      <td>0.954056</td>\n",
       "      <td>0.896364</td>\n",
       "      <td>0.947557</td>\n",
       "      <td>0.92125</td>\n",
       "      <td>0.915214</td>\n",
       "      <td>...</td>\n",
       "      <td>0.942271</td>\n",
       "      <td>0.912753</td>\n",
       "      <td>0.96931</td>\n",
       "      <td>0.940182</td>\n",
       "      <td>0.883897</td>\n",
       "      <td>0.965277</td>\n",
       "      <td>0.922797</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>0.922246</td>\n",
       "      <td>0.976129</td>\n",
       "      <td>0.948423</td>\n",
       "      <td>0.943517</td>\n",
       "      <td>0.984167</td>\n",
       "      <td>0.963413</td>\n",
       "      <td>0.925593</td>\n",
       "      <td>0.978828</td>\n",
       "      <td>0.951467</td>\n",
       "      <td>0.937615</td>\n",
       "      <td>...</td>\n",
       "      <td>0.964463</td>\n",
       "      <td>0.946201</td>\n",
       "      <td>0.983851</td>\n",
       "      <td>0.964659</td>\n",
       "      <td>0.917489</td>\n",
       "      <td>0.969316</td>\n",
       "      <td>0.942691</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>200</th>\n",
       "      <td>0.943976</td>\n",
       "      <td>0.987348</td>\n",
       "      <td>0.965175</td>\n",
       "      <td>0.95511</td>\n",
       "      <td>0.989976</td>\n",
       "      <td>0.97223</td>\n",
       "      <td>0.939596</td>\n",
       "      <td>0.987636</td>\n",
       "      <td>0.963017</td>\n",
       "      <td>0.947718</td>\n",
       "      <td>...</td>\n",
       "      <td>0.97218</td>\n",
       "      <td>0.951466</td>\n",
       "      <td>0.990464</td>\n",
       "      <td>0.970574</td>\n",
       "      <td>0.937942</td>\n",
       "      <td>0.979992</td>\n",
       "      <td>0.958506</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>500</th>\n",
       "      <td>0.954633</td>\n",
       "      <td>0.990899</td>\n",
       "      <td>0.972428</td>\n",
       "      <td>0.967176</td>\n",
       "      <td>0.992286</td>\n",
       "      <td>0.97957</td>\n",
       "      <td>0.958873</td>\n",
       "      <td>0.990798</td>\n",
       "      <td>0.974574</td>\n",
       "      <td>0.957006</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977912</td>\n",
       "      <td>0.960878</td>\n",
       "      <td>0.992171</td>\n",
       "      <td>0.976273</td>\n",
       "      <td>0.947592</td>\n",
       "      <td>0.987951</td>\n",
       "      <td>0.967351</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1000</th>\n",
       "      <td>0.963423</td>\n",
       "      <td>0.993588</td>\n",
       "      <td>0.978273</td>\n",
       "      <td>0.963837</td>\n",
       "      <td>0.992947</td>\n",
       "      <td>0.978176</td>\n",
       "      <td>0.962141</td>\n",
       "      <td>0.995074</td>\n",
       "      <td>0.97833</td>\n",
       "      <td>0.96326</td>\n",
       "      <td>...</td>\n",
       "      <td>0.978918</td>\n",
       "      <td>0.964487</td>\n",
       "      <td>0.992871</td>\n",
       "      <td>0.978473</td>\n",
       "      <td>0.959142</td>\n",
       "      <td>0.988411</td>\n",
       "      <td>0.973557</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3000</th>\n",
       "      <td>0.965487</td>\n",
       "      <td>0.993131</td>\n",
       "      <td>0.979114</td>\n",
       "      <td>0.964364</td>\n",
       "      <td>0.993589</td>\n",
       "      <td>0.978758</td>\n",
       "      <td>0.96489</td>\n",
       "      <td>0.993668</td>\n",
       "      <td>0.979067</td>\n",
       "      <td>0.962799</td>\n",
       "      <td>...</td>\n",
       "      <td>0.980586</td>\n",
       "      <td>0.968674</td>\n",
       "      <td>0.992681</td>\n",
       "      <td>0.980531</td>\n",
       "      <td>0.962524</td>\n",
       "      <td>0.98727</td>\n",
       "      <td>0.97474</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5000</th>\n",
       "      <td>0.966484</td>\n",
       "      <td>0.993112</td>\n",
       "      <td>0.979617</td>\n",
       "      <td>0.960239</td>\n",
       "      <td>0.99482</td>\n",
       "      <td>0.977223</td>\n",
       "      <td>0.957014</td>\n",
       "      <td>0.995237</td>\n",
       "      <td>0.975752</td>\n",
       "      <td>0.964064</td>\n",
       "      <td>...</td>\n",
       "      <td>0.981396</td>\n",
       "      <td>0.966375</td>\n",
       "      <td>0.992098</td>\n",
       "      <td>0.979067</td>\n",
       "      <td>0.956845</td>\n",
       "      <td>0.994011</td>\n",
       "      <td>0.975074</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10000</th>\n",
       "      <td>0.959505</td>\n",
       "      <td>0.99608</td>\n",
       "      <td>0.97745</td>\n",
       "      <td>0.960032</td>\n",
       "      <td>0.994313</td>\n",
       "      <td>0.976872</td>\n",
       "      <td>0.955316</td>\n",
       "      <td>0.996332</td>\n",
       "      <td>0.975393</td>\n",
       "      <td>0.96275</td>\n",
       "      <td>...</td>\n",
       "      <td>0.977591</td>\n",
       "      <td>0.961871</td>\n",
       "      <td>0.995203</td>\n",
       "      <td>0.978253</td>\n",
       "      <td>0.955449</td>\n",
       "      <td>0.993772</td>\n",
       "      <td>0.974234</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15000</th>\n",
       "      <td>0.954952</td>\n",
       "      <td>0.995338</td>\n",
       "      <td>0.974727</td>\n",
       "      <td>0.959434</td>\n",
       "      <td>0.99329</td>\n",
       "      <td>0.976068</td>\n",
       "      <td>0.955943</td>\n",
       "      <td>0.995768</td>\n",
       "      <td>0.975449</td>\n",
       "      <td>0.958507</td>\n",
       "      <td>...</td>\n",
       "      <td>0.979927</td>\n",
       "      <td>0.958888</td>\n",
       "      <td>0.99611</td>\n",
       "      <td>0.977144</td>\n",
       "      <td>0.955148</td>\n",
       "      <td>0.994681</td>\n",
       "      <td>0.974513</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25000</th>\n",
       "      <td>0.952577</td>\n",
       "      <td>0.995937</td>\n",
       "      <td>0.973775</td>\n",
       "      <td>0.958551</td>\n",
       "      <td>0.99508</td>\n",
       "      <td>0.976474</td>\n",
       "      <td>0.950643</td>\n",
       "      <td>0.996341</td>\n",
       "      <td>0.972955</td>\n",
       "      <td>0.960269</td>\n",
       "      <td>...</td>\n",
       "      <td>0.976291</td>\n",
       "      <td>0.957438</td>\n",
       "      <td>0.996344</td>\n",
       "      <td>0.976504</td>\n",
       "      <td>0.946697</td>\n",
       "      <td>0.993811</td>\n",
       "      <td>0.969682</td>\n",
       "      <td>0.953372</td>\n",
       "      <td>0.993934</td>\n",
       "      <td>0.97323</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>11 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      term_strength                          shap                      \\\n",
       "          precision    recall  f1-score precision    recall  f1-score   \n",
       "10         0.653981  0.759744  0.702906  0.840322  0.921833  0.879192   \n",
       "50         0.894914  0.951566  0.922371  0.932077  0.977095  0.954056   \n",
       "100        0.922246  0.976129  0.948423  0.943517  0.984167  0.963413   \n",
       "200        0.943976  0.987348  0.965175   0.95511  0.989976   0.97223   \n",
       "500        0.954633  0.990899  0.972428  0.967176  0.992286   0.97957   \n",
       "1000       0.963423  0.993588  0.978273  0.963837  0.992947  0.978176   \n",
       "3000       0.965487  0.993131  0.979114  0.964364  0.993589  0.978758   \n",
       "5000       0.966484  0.993112  0.979617  0.960239   0.99482  0.977223   \n",
       "10000      0.959505   0.99608   0.97745  0.960032  0.994313  0.976872   \n",
       "15000      0.954952  0.995338  0.974727  0.959434   0.99329  0.976068   \n",
       "25000      0.952577  0.995937  0.973775  0.958551   0.99508  0.976474   \n",
       "\n",
       "      linear_measure_5                          eccd  ... mutual_information  \\\n",
       "             precision    recall  f1-score precision  ...           f1-score   \n",
       "10            0.651361  0.779197  0.709567  0.744748  ...            0.83388   \n",
       "50            0.896364  0.947557   0.92125  0.915214  ...           0.942271   \n",
       "100           0.925593  0.978828  0.951467  0.937615  ...           0.964463   \n",
       "200           0.939596  0.987636  0.963017  0.947718  ...            0.97218   \n",
       "500           0.958873  0.990798  0.974574  0.957006  ...           0.977912   \n",
       "1000          0.962141  0.995074   0.97833   0.96326  ...           0.978918   \n",
       "3000           0.96489  0.993668  0.979067  0.962799  ...           0.980586   \n",
       "5000          0.957014  0.995237  0.975752  0.964064  ...           0.981396   \n",
       "10000         0.955316  0.996332  0.975393   0.96275  ...           0.977591   \n",
       "15000         0.955943  0.995768  0.975449  0.958507  ...           0.979927   \n",
       "25000         0.950643  0.996341  0.972955  0.960269  ...           0.976291   \n",
       "\n",
       "           chi2                         tfidf                      baseline  \\\n",
       "      precision    recall  f1-score precision    recall  f1-score precision   \n",
       "10     0.751019  0.937146  0.833822  0.702219  0.899003  0.788519  0.953372   \n",
       "50     0.912753   0.96931  0.940182  0.883897  0.965277  0.922797  0.953372   \n",
       "100    0.946201  0.983851  0.964659  0.917489  0.969316  0.942691  0.953372   \n",
       "200    0.951466  0.990464  0.970574  0.937942  0.979992  0.958506  0.953372   \n",
       "500    0.960878  0.992171  0.976273  0.947592  0.987951  0.967351  0.953372   \n",
       "1000   0.964487  0.992871  0.978473  0.959142  0.988411  0.973557  0.953372   \n",
       "3000   0.968674  0.992681  0.980531  0.962524   0.98727   0.97474  0.953372   \n",
       "5000   0.966375  0.992098  0.979067  0.956845  0.994011  0.975074  0.953372   \n",
       "10000  0.961871  0.995203  0.978253  0.955449  0.993772  0.974234  0.953372   \n",
       "15000  0.958888   0.99611  0.977144  0.955148  0.994681  0.974513  0.953372   \n",
       "25000  0.957438  0.996344  0.976504  0.946697  0.993811  0.969682  0.953372   \n",
       "\n",
       "                          \n",
       "         recall f1-score  \n",
       "10     0.993934  0.97323  \n",
       "50     0.993934  0.97323  \n",
       "100    0.993934  0.97323  \n",
       "200    0.993934  0.97323  \n",
       "500    0.993934  0.97323  \n",
       "1000   0.993934  0.97323  \n",
       "3000   0.993934  0.97323  \n",
       "5000   0.993934  0.97323  \n",
       "10000  0.993934  0.97323  \n",
       "15000  0.993934  0.97323  \n",
       "25000  0.993934  0.97323  \n",
       "\n",
       "[11 rows x 30 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10 (main, Jan 15 2022, 11:48:00) \n[Clang 13.0.0 (clang-1300.0.29.3)]"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
